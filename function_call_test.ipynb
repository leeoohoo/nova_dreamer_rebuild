{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a78544",
   "metadata": {},
   "source": [
    "# OpenAI Function Calling Test\n",
    "\n",
    "This notebook tests function calling against `https://relay.nf.video/v1` using the OpenAI SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4711d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 14:06:15,998 INFO function_call_test: Using base_url=https://relay.nf.video/v1 model=gpt-5.2-codex\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s: %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(\"function_call_test\")\n",
    "\n",
    "BASE_URL = \"https://relay.nf.video/v1\"\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-5.2-codex\")\n",
    "api_key = \"sk-ant-sid01--755be09a1ffba426ab33402481798b1a2676e29019a500b1a83e5e7e759c2fed\"\n",
    "\n",
    "if not api_key:\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY is not set.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=BASE_URL, timeout=60)\n",
    "logger.info(\"Using base_url=%s model=%s\", BASE_URL, MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 14:06:56,432 INFO httpx: HTTP Request: POST https://relay.nf.video/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-22 14:06:57,335 INFO function_call_test: Assistant message: ChatCompletionMessage(content='<think>**Identifying missing tool**</think>\\n\\n', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_N6M35faIzXaD85bdyrdIGUhn', function=Function(arguments='{\"location\":\"Beijing\",\"unit\":\"celsius\"}', name='get_weather'), type='function', index=0)])\n",
      "2026-01-22 14:06:57,336 INFO function_call_test: Tool result: {'location': 'Beijing', 'unit': 'celsius', 'temperature': 22, 'condition': 'sunny'}\n",
      "2026-01-22 14:07:04,111 INFO httpx: HTTP Request: POST https://relay.nf.video/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-22 14:07:04,115 INFO function_call_test: Follow-up response: <think>**Noticing network access limitation**\n",
      "\n",
      "The user inquiry about weather requires network access, which isn't available, so I'll need to inform them that fetching live data isn't possible without permission.</think>\n",
      "\n",
      "I can check live weather, but I need network access. Want me to fetch it?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Define a list of callable tools for the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_horoscope\",\n",
    "        \"description\": \"Get today's horoscope for an astrological sign.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sign\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"An astrological sign like Taurus or Aquarius\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sign\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "def get_horoscope(sign):\n",
    "    return f\"{sign}: Next Tuesday you will befriend a baby otter.\"\n",
    "\n",
    "# Create a running input list we will add to over time\n",
    "input_list = [\n",
    "    {\"role\": \"user\", \"content\": \"What is my horoscope? I am an Aquarius.\"}\n",
    "]\n",
    "\n",
    "# 2. Prompt the model with tools defined\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    ")\n",
    "\n",
    "# Save function call outputs for subsequent requests\n",
    "input_list += response.output\n",
    "\n",
    "for item in response.output:\n",
    "    if item.type == \"function_call\":\n",
    "        if item.name == \"get_horoscope\":\n",
    "            # 3. Execute the function logic for get_horoscope\n",
    "            horoscope = get_horoscope(json.loads(item.arguments))\n",
    "            \n",
    "            # 4. Provide function call results to the model\n",
    "            input_list.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": json.dumps({\n",
    "                  \"horoscope\": horoscope\n",
    "                })\n",
    "            })\n",
    "\n",
    "print(\"Final input:\")\n",
    "print(input_list)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    instructions=\"Respond only with a horoscope generated by a tool.\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    ")\n",
    "\n",
    "# 5. The model should be able to give a response!\n",
    "print(\"Final output:\")\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(\"\\n\" + response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce9131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
